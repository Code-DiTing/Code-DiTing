<p align="center">
    <a href="#-features">🚀 Features</a> •
    <a href="#-dataset">🤗 DataSet & Models</a> •
    <a href="#-quick-start">🔥 Quick Start</a> •
    <a href="#-citation">📜 Citation</a>
    <a href="#-license">📝 License</a>
</p>

**CODE-DITING** is a novel code generation evaluation metric that directly assesses the functional alignment between problem descriptions and generated code. 
This approach overcomes the limitations of traditional reference solutions and test case methods. While maintaining high accuracy, it achieves efficient computational performance and provides excellent explainability.

## 🚀 Features
- *Accuracy*: CODE-DITING outperforms existing state-of-the-art methods across multiple datasets.
- *Efficiency*: Using smaller models (1.5B and 7B parameter scale), it achieves comparable or even superior results to large-scale models (such as GPT-4o and DeepSeek-V3 671B) with only about 1% of the parameter count.
- *Explainability*: By introducing reasoning paths, the evaluation process becomes more transparent, making it easier to understand the basis for the model's judgments.

## 🤗 DataSet & Models
We provide datasets for training and evaluation, as well as pre-trained models:

- **Datasets**:
  - [CodeJudge](https://www.modelscope.cn/datasets/CodeDiTing/CodeJudge_17k) - Dataset for training
  - [HumanEval-Judge](https://huggingface.co/datasets/CodeDiTing/HumanEval-Judge) - Dataset for HumanEval-Judge evaluation
  - [MBPP-Judge](https://huggingface.co/datasets/CodeDiTing/MBPP-Judge) - Dataset for MBPP-Judge evaluation
  - [BigCodeBench-Judge](https://huggingface.co/datasets/CodeDiTing/BigCodeBench-Judge) - Dataset for BigCodeBench-Judge evaluation

- **Models**:
  - [CODE-DITING-1.5B](https://www.modelscope.cn/models/CodeDiTing/Code-DiTing-1.5B) - 1.5B parameter model
  - [CODE-DITING-7B](https://www.modelscope.cn/models/CodeDiTing/Code-DiTing-7B) - 7B parameter model

## 🔥 Quick Start

wait updating...

## 📜 Citation

If you find this work useful, please consider citing:

wait updating...


## 📝 License
This project is licensed under the [MIT License](LICENSE).

<!-- ## 🙏 Acknowledgements
We thank all researchers and developers who contributed to this project. Special thanks to [Institution/Organization Name] for their support. -->
